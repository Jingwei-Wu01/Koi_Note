

### **对话系统**

任务导向型：管道型和端到端
非任务导向型（聊天机器人）：检索、文本生成、检索结合生成

情感对话任务：1. 对话情绪感知（情感分类） **2. 情感对话生成/响应（生成具有情感的回复）**

#### 情感对话响应任务发展

1. 对话机器人
   聊天机器人 Eliza

2. 基于规则和统计的情感对话机器人
   首个情感对话机器人Parry（启发式模板匹配）
   启发式模板匹配的机器人ALICE
   具有完整人工智能架构的 机器人小冰

3. 基于深度学习的问答系统
   **深度情感对话响应任务**基于**<u>深度问答任务</u>**（基于表示的模型、基于交互的模型和混合模型）

   基于表示的模型

   基于交互的模型

   ABCNN

4. 基于深度学习的情感对话响应模型
   可控情感对话生成模型ECM
   共情对话模型EmoPrepend-1
   情绪支持模型Emo-HRED
   多模态情感对话生成模型
   多人共情对话任务
   价值任务
   减轻语言毒性任务

#### 基于深度学习的情感对话响应模型

##### 子任务

按照融入情绪的目的不同，将模型分为可控情感对话生成、共情对话响应、情绪支持、多模态情感对话生成四个方面。

###### 基于文本模态

1. **可控情感对话生成**：如何在对话中表达指定类型的情绪 
   *用户指定情感*

   **Seq2seq**

   **情绪感知模型**  [28-35] 

   > 该类模型的另一个优势是在在编码过程中能够注重到词粒度的语义和情感的关联，有利于情感的准确表达。但由于回复是直接由解码器生成，在编码器中指定情绪则只能较为间接的表达情感。
   >
   > ```
   > 优点:方法简易;能融合词粒度情感和语义
   > 缺点:间接指定情感
   > ```

   **情绪表示模型** [36-44]

   > 在解码器中考虑情感因素能使情 感较为直接地表达在回复中。但这种表达方式不 能产生共情的回复，也并不能结合对话历史的情 感表达更为自然的情感。
   >
   > ```
   > 优点:直接指定情感
   > 缺点:不能结合对话历史的细粒度情感
   > ```

   **情绪感知表示模型** [45-54]

   > 情绪感知表示模型融合 了两类模型的优势，但正因为在模型既能感知对 话中的情绪，又需要表达指定的情绪，若两者之 间的情绪不一致，则会影响情绪在回复的表达。
   >
   > ```
   > 优点:结合了两类的优势
   > 缺点:易引入噪音
   > ```

   

2. ###### **共情对话响应**：模型具有感知说话者情绪，并表达合适情绪的能力（在未给定情绪标签的情况下正确感知说话者的情绪，通过将感知到的情绪合理表达于回复中，使模型具备同理心）

   *自动感知用户所表达的情感*

   大量的生成式模型，同时也包含了少量的检索式、检索结合生成式模型

   **基于情绪因素的模型**  (seq2seq)

   1. 话语级情绪(Dialogue-Level Emotion) [57-60]

      > 考虑细致情绪
      >
      > ```
      > 优点:融入了全局情绪
      > 缺点:较为粗糙;忽略了混合情绪
      > ```

   2. 混合情绪(Mixed Emotions) [61, 62]

      注重话语级情绪的 模型仅将某种情绪作为生成回复的引导因素，而注重混合情绪的模型则模拟了人类表达混合情绪的特性，以多种混合情绪引导回复生成。

      <u>多解码器</u>

      ```
      优点:更复合人类情感表达习惯
      缺点:未注意细微情绪
      ```

   3. 词级情绪(Word-Level Emotion) [63-68]

      识别情绪的诱发词etc

      ```
      优点:细致易捕捉
      缺点:忽略了混合情绪
      ```

   4. 情绪关联 [69-79]：

      查询和回复之间的一致性 (Consistency)和转移性(Transition)

      ```
      优点:关注了情绪的一致性或转移性
      缺点:忽略了细微情绪及混合情绪
      ```

   **基于复合因素的模型** (seq2seq)

   1. 常识(Commonsense Knowledge) [56, 80-83]
   2. 意图(Intent) [84]
   3. 个人特质 (Personality) [85-87]
   4. 对话主题(Topic) [88-90]
   5. 多种因素 [78, 90, 91]：沟通机制、对话动作 (dialog act)和情绪(emotion)

   **基于结构因素的模型**

   1. 检索式
   2. 检索结合生成式
   3. 模板填充式

   `目前的模型大多为生成式模型，而检索式、检索结合生成式模型::哪些是生成式`

3. **<u>情绪支持（！）</u>**：模型具备一定程度的同理心，同时也要求模型能够通过对话给予说话者一定的精神支持和安慰，并起到一定的心理慰藉作用。情绪支持旨在调节说话者的情绪以慰藉或降低说话者负面情绪。本节将情绪支持的模型分为三类:激发积极情绪、激发指定情绪、降低负面情绪。
   *激发特定的情绪$𝐸_r$来慰藉说话者*

   1. 激发积极情绪 [96-**101**]
   2. 激发指定情绪 [97, **103**]
   3. 降低负面情绪 [104-**106**]

   难点：如何有效的评估慰藉效果

   未来：如何结合多种因素有效地调节说话者情绪以起到心理健康支持

###### 基于多模态的情感对话生成任务 & 新任务

1. **多模态情感对话生成** [107-110]：图像和文字/表情、情感和 人物特质(某人所说的全部话语)与共情对话/音频及音频之间的关联 （相比于 Huber 等人(2018)将多模态信息进行了简单的融合，后面两种<u>以图构建模态间关联</u>的方式更为精细复杂。）
2. **多人共情对话** [111]： 此外该研究认为序列到序列模型在多轮对话具有一定的限制，同时也认为不同参与者之间会互相影响。因此该模型采用动态图网络构建了多方对话，随后融合了说话者的信息来探索对话的情感。
3. **价值任务** [112]：价值指的是在人们生活中想要完 成的目标，它影响着人们对于行动、策略、人物 和事件的选择和评估
4. **减轻语言毒性** [114]：有毒的语言通常被描述为骚扰或攻击性语言，它降低了对话者交流和合作的可能性。共情和毒性有着负相关的关系，并发现共情可以减缓毒性语言的发生。为检验模型的有效性，该研究首先将微调后的语言模型和未微调的语言模型的预测概率按权相加以生成回复，随后调整权重以观察生成回复的毒性是否合理的改变。

##### 模型结构

情感对话响应任务：对话、情感分析、检索和生成

1. 检索式模型 [93]

   检索式模型首先需要构造候选的数据 库，随后通过文本匹配的方式从数据集中搜索出情感和内容都适合的文本作为回复。检索式模型产出的回复质量较依赖于候选集的质量。

2. 生成式模型（seq2seq/LSTM/GRU/HRED-->Transformer）

   构建生成式模型的方式例如改进编码器或解码器、微调预训练模型、在序列到序列架构上加入更多的模块以增强回复的情感。

3. 检索融合生成模型

   

> Seq2seq (RNN/Transformer)
>
> 基于输入序列的改进模型，基于编码器的改进模型，基于解码器的改进模型
>
> Pre-train
> 预训练-->微调（预训练模型一般在大数据上训练至收敛后，再将其运用在对话数据上微调。早期时，模型在微调时除了预测回复任务以外，仅将情感分类作为其他任务协同训练。随着时间的发展，研究者们加入了更多的任务以微调模型， 例如加入粗/细粒度的情感分类，下一个句子是否正确的分类任务。）
>
> GAN
> 判别器（早期模型的判别器仅依靠生成与标准回复判别真伪，后来也结合对话历史、回复的反馈语句等信息使判别器有更多的判别依据。）
>
> Reinforcement learning
> 环境（早期方法仅将情感因素考虑到环境中，之后的模型考虑了例如流利度、主题关联度等更复杂的因素）
>
> Dual learning （对偶学习）
> 对偶式方法不仅考虑了查询到回复的关系，也考虑了回复到查询的关联，以强化查询和回复之间的情感和内容的一致性。

